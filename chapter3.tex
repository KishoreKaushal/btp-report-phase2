\chapter{JPEG}

\section{Overview}

JPEG, which stands for Joint Photographic Experts Group (the name of the committee that created the JPEG standard) is a lossy compression algorithm for images. A lossy compression scheme is a way to inexactly represent the data in the image, such that less memory is used yet the data appears to be very similar. This is why JPEG images look almost the same as the original images they were derived from most of the time unless the quality is reduced significantly, in which case there will be visible differences.

The JPEG algorithm takes advantage of the fact that humans can't see colors at high frequencies. These high frequencies are the data points in the image that are eliminated during the compression. JPEG compression also works best on images with smooth colour transitions.

JPEG is a commonly used method of lossy compression for digital
images. The degree of compression can be adjusted, allowing a
the tradeoff between storage size and image quality with a
compression ratio 10:1 but with little perceptible loss in image
quality.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.40\textwidth]{fig/3-1.png}
    \captionsource{A photo of a European wildcat with the compression rate decreasing and hence quality increasing, from left to right.}
    {\url{https://en.wikipedia.org/wiki/JPEG}}
    \label{fig:jpegCompression}
\end{figure}

\vspace{2em}

\section{Algorithm}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.80\textwidth]{fig/3-2.png}
    \caption{JPEG Schematic}
    \label{fig:jpegSchematic}
\end{figure}


\subsection{Splitting}

JPEG uses transform coding, it is largely based on the following observations:

\begin{itemize}
    \item Usually image contents change relatively slowly across images, i.e., it is unusual for intensity values to alter up and down several times in a small area, for example, within an $8 \times 8$ image block. A translation of this fact into the spatial frequency domain, implies, generally, lower spatial  frequency components contain more information than the high frequency components which often correspond to less useful details and noises.
    \item Experiments suggest that humans are more immune to loss of higher spatial frequency components than loss of lower frequency components. Human vision is insensitive to high frequency components.
\end{itemize}

Hence, first step is to split the image into $8 \times 8$ blocks non-overlapping pixel blocks. If the image cannot be divided into $8 \times 8$ blocks then the block is zero padded.

\vspace{1em}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.50\textwidth]{fig/3-3.png}
    \caption{Splitting into $8 \times 8$ blocks}
    \label{fig:splitting}
\end{figure}

\subsection{Color Space Transform}

JPEG makes use of $[Y, Cb, Cr]$ model instead of $[R, G, B]$ model. There is a reason for using the color space. The human eye is more sensitive to luminance than to chrominance. 

\begingroup
\centering
    \begin{tabular}{|l|}
    \hline
    $Y = 0.299R + 0.587G + 0.114B$              \\ \hline
    $Cb = -0.1687R - 0.3313G + 0.5B + 128$      \\ \hline
    $Cr = 0.5R - 0.4187G - 0.0813B + 128$       \\ \hline
    $R = Y + 1.402 (Cr - 128)$                   \\ \hline
    $G = Y - 0.34414 (Cb - 128) - 0.71414(Cr - 128)$ \\ \hline
    $B = Y + 1.772  (Cb - 128)$                   \\ \hline
    \end{tabular}
\captionof{table}{RGB and YCbCr conversion table}\label{tbl:RGBYCbCrTable}
\endgroup


\subsection{Down-sampling}

After the color space transformation, the image is downsampled.
Downsampling happens in such a way that $Y$ is taken for each pixel whereas $Cb$ and $Cr$ are taken for $2 \times 2$ blocks.

Sometimes this step is not carried out(baseline JPEG).

\subsection{Discrete Cosine Transform}

The key to the JPEG baseline compression process is a mathematical transformation known as the Discrete Cosine Transform (DCT). The DCT is in a class of mathematical operations that includes the well known Fast Fourier Transform (FFT), as well as many others. The basic purpose of these operations is to take a signal and transform it from one type of representation to another. For example, an image is a two-dimensional signal that is perceived by the human visual system. The DCT can be used to convert the signal (spatial information) into numeric data (“frequency” or “spectral” information) so that the image's information exists in a quantitative form that can be manipulated for compression.

The DCT is performed on a $N \times N$ square matrix of pixel values, and it yields a $N \times N$ square matrix of frequency coefficients. (In practice, N most often equals 8 because a larger block, though would probably give better compression, often takes a great deal of time to perform DCT calculations, creating an unreasonable tradeoff. As a result, DCT implementations typically break the image down into more manageable $8 \times 8$ blocks.) The DCT formula \ref{eq:DCTFormula} looks somewhat intimidating at first glance but can be implemented with a relatively straightforward piece of code.

\begin{equation}
    \begin{split}
    DCT[i,j] = \frac{1}{\sqrt{2N}} \: C[i] \: C[j] \; \sum_{x=0}^{N-1} \sum_{y=0}^{N-1} \; I[x,y] \: cos[\frac{(2x + 1)i\pi}{2N}] \: cos[\frac{(2y + 1)j\pi}{2N}]  \\
    where \; C(x) = \frac{1}{\sqrt{2}} \; if \; x=0, \; else \;1 \; if \; x>0
    \end{split}
    \label{eq:DCTFormula}
\end{equation}

Below are two matrices representing the DCT input \ref{eq:8x8block} and DCT output blocks \ref{eq:DCTTransform} from a gray-scale image. Each element of the 8-pixel-by-8-pixel input matrix contains the value of the pixel at the corresponding $(x, y)$ location. These integer values are fed to the DCT algorithm, creating the output matrix shown below it. Each element of the output matrix is a coefficient by which the waveform of the corresponding spatial frequency is multiplied in the decomposition of the image sample.

\begin{equation}
    \begin{bmatrix}
        140 & 144 & 147 & 140 & 140 & 155 & 179 & 175\\ 
        144 & 152 & 140 & 147 & 140 & 148 & 167 & 179\\ 
        152 & 155 & 136 & 167 & 163 & 162 & 152 & 172\\ 
        168 & 145 & 156 & 160 & 152 & 155 & 136 & 160\\ 
        162 & 148 & 156 & 148 & 140 & 136 & 147 & 162\\ 
        147 & 167 & 140 & 155 & 155 & 140 & 136 & 162\\ 
        136 & 156 & 123 & 167 & 162 & 144 & 140 & 147\\ 
        148 & 155 & 136 & 155 & 152 & 147 & 147 & 136
    \end{bmatrix}
    \label{eq:8x8block}   
\end{equation}

Why DCT? Human vision is insensitive to high-frequency components, due to which it is possible to treat the data corresponding to high frequencies as redundant. To segregate the raw image data on the basis of frequency, it needs to be converted into frequency domain, which is the primary function of DCT.

\begin{equation}
    \begin{bmatrix}
        1209 & -17 & 14 & -8 & 23 & -9 & -13 & -18 \\
        20 & -34 & 26 & -9 & -10 & 10 & 13 & 6 \\
        -10 & -23 & -1 & 6 & -18 & 3 & -20 & 0 \\
        -8 & -5 & 14 & -14 & -8 & -2 & -3 & 8 \\
        -3 & 9 & 7 & 1 & -10 & 17 & 18 & 15 \\
        3 & -2 & -18 & 8 & 8 & -3 & 0 & -6 \\
        8 & 0 & -2 & 3 & -1 & -7 & -1 & -1 \\
        0 & -7 & -2 & 1 & 1 & 4 & -6 & 0
    \end{bmatrix}
    \label{eq:DCTTransform}
\end{equation}

\subsection{Coefficient Quantization}

Humans are unable to see aspects of an image that are at really high frequencies. Since taking the DCT allows us to isolate where these high frequencies are, we can take advantage of this in choosing which values to preserve. By multiplying the DCT matrix by some mask, we can zero out elements of the matrix, thereby freeing the memory that had been representing those values. The resultant quantize matrix will only preserve values at the lowest frequencies up to a certain point.

\begin{equation}
    \begin{split}
        DCT_q[i,j] = \left \lfloor \frac{DCT[i,j]}{Q[i,j]} \right \rceil
    \end{split}
    \label{eq:quantizationFormula}
\end{equation}

In Eq. \ref{eq:quantizationFormula} $Q$ is the quantization matrix. JPEG Standard defines two default quantization tables, one each for luminance and chrominance. From the formula, one can notice the smaller DCT coefficients of high-frequency elements divided by the larger quantum values will most often result in the high-frequency coefficients being rounded down to zero.

\begingroup
\centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|}
    \hline
    16 & 11 & 10 & 16 & 24  & 40  & 51  & 61  \\ \hline
    12 & 12 & 14 & 19 & 26  & 58  & 60  & 55  \\ \hline
    14 & 13 & 16 & 24 & 40  & 57  & 69  & 56  \\ \hline
    14 & 17 & 22 & 29 & 51  & 87  & 80  & 62  \\ \hline
    18 & 22 & 37 & 56 & 68  & 109 & 103 & 77  \\ \hline
    24 & 35 & 55 & 64 & 81  & 104 & 113 & 92  \\ \hline
    49 & 64 & 78 & 87 & 103 & 121 & 120 & 101 \\ \hline
    72 & 92 & 95 & 98 & 112 & 100 & 103 & 99  \\ \hline
    \end{tabular}
    \captionof{table}{Luminance Quantization Table}\label{tbl:LuminanceQuantTable}
\endgroup

\vspace{2em}

\begingroup
\centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|}
    \hline
    17 & 18 & 24 & 47 & 99 & 99 & 99 & 99 \\ \hline
    18 & 21 & 26 & 66 & 99 & 99 & 99 & 99 \\ \hline
    24 & 26 & 56 & 99 & 99 & 99 & 99 & 99 \\ \hline
    47 & 66 & 99 & 99 & 99 & 99 & 99 & 99 \\ \hline
    99 & 99 & 99 & 99 & 99 & 99 & 99 & 99 \\ \hline
    99 & 99 & 99 & 99 & 99 & 99 & 99 & 99 \\ \hline
    99 & 99 & 99 & 99 & 99 & 99 & 99 & 99 \\ \hline
    99 & 99 & 99 & 99 & 99 & 99 & 99 & 99 \\ \hline
    \end{tabular}
    \captionof{table}{Chrominance Quantization  Table}\label{tbl:ChrominanceQuantTable}
\endgroup

The quantization step is the major information losing step in JPEG
compression.


\subsection{Encoding}

The final step of the JPEG image compression process is to compress the quantized DCT values. This is done through a three-part procedure detailed below.

First, the DC coefficient is changed from absolute value to a relative value – relative to the DC coefficient in the previous $8 \times 8$ block, that is. Since adjacent blocks in an image exhibit a high degree of correlation, coding the DC term of a given block as the difference from the previous DC term typically produces a very small number that can be stored in a fewer number of bits.

Second, reorder the DCT block in a zig-zag sequence. Because so many coefficients in the DCT image are truncated to zero values during the coefficient quantization stage, the zeros are handled differently than non-zero coefficients. They are coded using a Run-Length Encoding (RLE) algorithm. RLE gives a count of consecutive zero values in the image, and the longer the runs of zeros, the greater the compression. One way to increase the length of runs is to reorder the coefficients in the zig-zag sequence shown in the diagram below. This way, the JPEG algorithm moves through the block selecting the highest value elements first and eventually working its way to the lowest value elements, thus optimizing the effect of RLE.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.50\textwidth]{fig/3-4.png}
    \captionsource{Reorder the DCT block in a zig-zag sequence}{\href{https://www.freecodecamp.org/news/how-jpg-works-a4dbd2316f35/}{freecodecamp.org/}}
    \label{fig:zig-zag}
\end{figure}

Third, Entropy Encoding. Finally, the JPEG algorithm outputs the DCT block's elements using an entropy encoding mechanism that combines the principles of RLE and Huffman encoding. The output of the entropy encoder consists of a sequence of three tokens, repeated until the block is complete. The three tokens are the run length, the number of consecutive zeros that precede the current non-zero element in the DCT output matrix; the bit count, the number of bits used to encode the amplitude value that follows, as determined by the Huffman encoding scheme; and the amplitude, the amplitude of the DCT coefficient.

The final output that results from JPEG compression can be mathematically reversed and decompressed to produce an image that, to a computer, lacks defining data, but to a human eye, it appears identical to the original image.

\section{Conclusion}
In this chapter, we proposed a distributed algorithm
for construction of xyz.
The complexity of this algorithm is $O(n \log n)$.
Next chapter presents
another distributed algorithm which has linear time 
complexity based on xyz.

